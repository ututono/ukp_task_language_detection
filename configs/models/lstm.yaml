classifier_type: "lstm"
model_type: "lstm"

# Text encoding
encoding_type: "char"  # char or word
vocab_size: 1000
max_length: 200

# Embedding layer
embedding_dim: 64

# LSTM parameters
hidden_dim: 256
num_layers: 2
bidirectional: true
dropout: 0.2

# Training parameters
learning_rate: 0.001
batch_size: 256
epochs: 5
